{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61c20e7d-2a43-4bdb-9aa5-72f4690e91af",
   "metadata": {},
   "source": [
    "# Part 1: How to get the same New York 2017 dataset with 157269 rows that is usually used in articles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521730a4-527e-4895-89aa-d2ec7c00100a",
   "metadata": {},
   "source": [
    "All original datasets can be downloaded from here: https://www.consumerfinance.gov/data-research/hmda/historic-data/ (use 'All Records' and 'Plain language' options)\n",
    "\n",
    "Download datasets Data_lending and hmda_2017_ny_all-records_labels for this guide from here: https://drive.google.com/drive/folders/1ctZxncnxScM5q49V3X2iaFjmW6K9CVf7?usp=drive_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0281f690-4a9e-4ce9-8e46-d6fbf8091e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New York Article dataset has 157269 rows and 60 columns\n",
      "New York Original dataset has 446902 rows and 78 columns\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_article = pd.read_csv(\"Data_lending.csv\", low_memory=False)\n",
    "print(\"New York Article dataset has {} rows and {} columns\".format(data_article.shape[0], data_article.shape[1]))\n",
    "\n",
    "data_original = pd.read_csv(\"hmda_2017_ny_all-records_labels.csv\", low_memory=False)\n",
    "print(\"New York Original dataset has {} rows and {} columns\".format(data_original.shape[0], data_original.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ece98c9-2558-447d-8261-cc7a29a565a7",
   "metadata": {},
   "source": [
    "We begin by identifying and removing any columns that are unique to the original New York dataset, so they are not used in New York Article data. \n",
    "Also we remove 3 artificial columns (response variable which has the same meaning as action_taken and 2 columns with numbers of rows) from the New York Article dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a60b8229-c0b9-453f-b72f-c756ed0df44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns presented only in New York Article dataset: {'response', 'X', 'Unnamed: 0'}\n",
      "Columns presented only in New York Original dataset: {'preapproval', 'state_abbr', 'edit_status', 'owner_occupancy_name', 'preapproval_name', 'hoepa_status_name', 'hoepa_status', 'edit_status_name', 'state_name', 'sequence_number', 'agency_abbr', 'owner_occupancy', 'state_code', 'agency_code', 'as_of_year', 'applicant_sex', 'co_applicant_sex', 'property_type_name', 'property_type', 'application_date_indicator', 'agency_name'}\n"
     ]
    }
   ],
   "source": [
    "columns_article = set(data_article.columns)\n",
    "columns_original = set(data_original.columns)\n",
    "\n",
    "unique_article = columns_article - columns_original\n",
    "unique_original = columns_original - columns_article\n",
    "\n",
    "print(\"Columns presented only in New York Article dataset:\", unique_article)\n",
    "print(\"Columns presented only in New York Original dataset:\", unique_original)\n",
    "\n",
    "data_article = data_article.drop(columns=unique_article)\n",
    "data_original = data_original.drop(columns=unique_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5ad1f2-9059-4911-84a5-608c9dfaf08e",
   "metadata": {},
   "source": [
    "Next we identify which categorical values were excluded. We apply the same method to each object-type column (excluding respondent_id). And after we remove rows with these values from original New York data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8de49f62-8029-46ed-ada8-88d55f1ae1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column: loan_type_name\n",
      "Only in New York Original: {'FSA/RHS-guaranteed', 'VA-guaranteed'}\n",
      "\n",
      "Column: loan_purpose_name\n",
      "Only in New York Original: {'Home improvement'}\n",
      "\n",
      "Column: action_taken_name\n",
      "Only in New York Original: {'File closed for incompleteness', 'Preapproval request denied by financial institution', 'Loan purchased by the institution', 'Application withdrawn by applicant', 'Application denied by financial institution', 'Preapproval request approved but not accepted'}\n",
      "\n",
      "Column: applicant_race_name_1\n",
      "Only in New York Original: {'American Indian or Alaska Native', 'Native Hawaiian or Other Pacific Islander', 'Information not provided by applicant in mail, Internet, or telephone application', 'Not applicable', 'Asian'}\n",
      "\n",
      "Column: applicant_sex_name\n",
      "Only in New York Original: {'Information not provided by applicant in mail, Internet, or telephone application', 'Not applicable'}\n"
     ]
    }
   ],
   "source": [
    "object_columns = data_article.select_dtypes(include='object').columns\n",
    "object_columns = [col for col in object_columns if col != 'respondent_id']\n",
    "\n",
    "for col in object_columns:\n",
    "    article = set(data_article[col].dropna().unique())\n",
    "    original = set(data_original[col].dropna().unique())\n",
    "    only_original = original - article\n",
    "\n",
    "    if only_original:\n",
    "        print(f\"\\nColumn: {col}\")\n",
    "        print(\"Only in New York Original:\", only_original)\n",
    "        \n",
    "        data_original = data_original[~data_original[col].isin(only_original)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "709bb840-c25a-4a5f-b92c-7ad17e6a8858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157269, 57)\n",
      "(162282, 57)\n"
     ]
    }
   ],
   "source": [
    "print(data_article.shape)\n",
    "print(data_original.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4e5f3d-77e2-41fe-ad1e-084b6b9b48c9",
   "metadata": {},
   "source": [
    "We are left with only 5,013 differing rows between the two datasets. Now we will compare each column and determine where the amount of unique values differs by the exact value of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab86aa97-7d41-4bc0-b7e5-ef585a1386c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: applicant_income_000s — 5013 values not found in New York Article (the exact amount)\n",
      "Series([], Name: count, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "expected_diff = data_original.shape[0] - data_article.shape[0]\n",
    "\n",
    "for col in data_original.columns:\n",
    "    values_in_article = set(data_article[col].dropna().unique())\n",
    "    mask = ~data_original[col].isin(values_in_article)\n",
    "    count = mask.sum()\n",
    "\n",
    "    if count == expected_diff:\n",
    "        print(f\"Column: {col} — {count} values not found in New York Article (the exact amount)\")\n",
    "\n",
    "article = set(data_article['applicant_income_000s'])\n",
    "original = set(data_original['applicant_income_000s'])\n",
    "\n",
    "only_original = original - article\n",
    "unique_original = data_original[data_original['applicant_income_000s'].isin(only_original)]\n",
    "print(unique_original['applicant_income_000s'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56907e41-b2e3-445c-8913-e0c3de5f5734",
   "metadata": {},
   "source": [
    "We found the column which is responsible for the remaining 5,013 rows. As the final cleaning step, we remove these rows from the dataset which results in two fully matched datasets (all these rows are missing data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "660536d5-b99f-4761-9d06-9e53f02b24ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157269, 57)\n",
      "(157269, 57)\n"
     ]
    }
   ],
   "source": [
    "data_original['applicant_income_000s'] = data_original['applicant_income_000s'].replace('', np.nan)\n",
    "data_original = data_original[~data_original['applicant_income_000s'].isna()]\n",
    "\n",
    "print(data_article.shape)\n",
    "print(data_original.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920447d9-69fe-40f1-8639-6974c123d936",
   "metadata": {},
   "source": [
    "Overall, there are some differences in numerical values within certain categorical columns and in client identifiers, but both datasets are fundamentally equivalent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd057f90-df5a-4936-a841-d6e305e30858",
   "metadata": {},
   "source": [
    "## Part 2: Fixing action_taken Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bad82253-a160-4888-bf48-a7f274ca2365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New York Original dataset has 446902 rows and 78 columns\n",
      "Response definition in New York Article action_taken_name\n",
      "Loan originated                          147255\n",
      "Application approved but not accepted     10014\n",
      "Name: count, dtype: int64\n",
      "Response definition in New York Original action_taken_name\n",
      "Loan originated                                        236499\n",
      "Application denied by financial institution             68255\n",
      "Loan purchased by the institution                       59584\n",
      "Application withdrawn by applicant                      47506\n",
      "File closed for incompleteness                          19397\n",
      "Application approved but not accepted                   15647\n",
      "Preapproval request denied by financial institution        11\n",
      "Preapproval request approved but not accepted               3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data_original = pd.read_csv(\"hmda_2017_ny_all-records_labels.csv\", low_memory=False)\n",
    "print(\"New York Original dataset has {} rows and {} columns\".format(data_original.shape[0], data_original.shape[1]))\n",
    "\n",
    "data_article = pd.read_csv(\"Data_lending.csv\", low_memory=False)\n",
    "\n",
    "print(f'Response definition in New York Article {data_article['action_taken_name'].value_counts()}')\n",
    "print(f'Response definition in New York Original {data_original['action_taken_name'].value_counts()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e57cc1-40c4-4833-adb7-bee2ba5341f1",
   "metadata": {},
   "source": [
    "When reviewing the credit decision data in the New York Article dataset, we can see that cases labeled as \"Application approved but not accepted\" were used instead of \"Application denied by financial institution.\"\n",
    "\n",
    "According to the official HMDA guidance https://www.consumerfinance.gov/rules-policy/regulations/1003/interp-4/, the category \"Application approved but not accepted\" may include situations where the applicant chooses not to proceed by his own decision or other non-standard scenarios. So it is more appropriate to use \"Application denied by financial institution\" as a more direct indicator of credit denial.\n",
    "\n",
    "So to replicate the dataset structure used in Part 1, but with a corrected action_taken variable, we only need to modify a small part of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a53c08d-d86a-47a3-817a-969d05889185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns presented only in New York Article dataset: {'response', 'X', 'Unnamed: 0'}\n",
      "Columns presented only in New York Original dataset: {'preapproval', 'state_abbr', 'edit_status', 'owner_occupancy_name', 'preapproval_name', 'hoepa_status_name', 'hoepa_status', 'edit_status_name', 'state_name', 'sequence_number', 'agency_abbr', 'owner_occupancy', 'state_code', 'agency_code', 'as_of_year', 'applicant_sex', 'co_applicant_sex', 'property_type_name', 'property_type', 'application_date_indicator', 'agency_name'}\n",
      "\n",
      "Column: loan_type_name\n",
      "Only in New York Original: {'FSA/RHS-guaranteed', 'VA-guaranteed'}\n",
      "\n",
      "Column: loan_purpose_name\n",
      "Only in New York Original: {'Home improvement'}\n",
      "\n",
      "Column: action_taken_name\n",
      "Only in New York Original: {'File closed for incompleteness', 'Preapproval request denied by financial institution', 'Loan purchased by the institution', 'Application withdrawn by applicant', 'Application denied by financial institution', 'Preapproval request approved but not accepted'}\n",
      "\n",
      "Column: applicant_race_name_1\n",
      "Only in New York Original: {'American Indian or Alaska Native', 'Native Hawaiian or Other Pacific Islander', 'Information not provided by applicant in mail, Internet, or telephone application', 'Not applicable', 'Asian'}\n",
      "\n",
      "Column: co_applicant_race_name_3\n",
      "Only in New York Original: {'Black or African American', 'Asian'}\n",
      "\n",
      "Column: applicant_sex_name\n",
      "Only in New York Original: {'Information not provided by applicant in mail, Internet, or telephone application', 'Not applicable'}\n",
      "(157269, 57)\n",
      "(180102, 57)\n"
     ]
    }
   ],
   "source": [
    "# First step\n",
    "columns_article = set(data_article.columns)\n",
    "columns_original = set(data_original.columns)\n",
    "\n",
    "unique_article = columns_article - columns_original\n",
    "unique_original = columns_original - columns_article\n",
    "\n",
    "print(\"Columns presented only in New York Article dataset:\", unique_article)\n",
    "print(\"Columns presented only in New York Original dataset:\", unique_original)\n",
    "\n",
    "data_article = data_article.drop(columns=unique_article)\n",
    "data_original = data_original.drop(columns=unique_original)\n",
    "\n",
    "# Second step\n",
    "object_columns = data_article.select_dtypes(include='object').columns\n",
    "object_columns = [col for col in object_columns if col != 'respondent_id']\n",
    "\n",
    "for col in object_columns:\n",
    "    article = set(data_article[col].dropna().unique())\n",
    "    original = set(data_original[col].dropna().unique())\n",
    "    only_original = original - article\n",
    "\n",
    "    if only_original:\n",
    "        print(f\"\\nColumn: {col}\")\n",
    "        print(\"Only in New York Original:\", only_original)\n",
    "\n",
    "        # Here is the additional code for fixing response variable\n",
    "        if col == 'action_taken_name':\n",
    "            values_to_delete = {'Application approved but not accepted', 'Loan purchased by the institution',\n",
    "                                'File closed for incompleteness', 'Preapproval request approved but not accepted',\n",
    "                                'Preapproval request denied by financial institution', 'Application withdrawn by applicant'}\n",
    "            data_original = data_original[~data_original[col].isin(values_to_delete)]\n",
    "        else:\n",
    "            # Default behavior for other columns\n",
    "            data_original = data_original[~data_original[col].isin(only_original)]\n",
    "# Third step\n",
    "data_original['applicant_income_000s'] = data_original['applicant_income_000s'].replace('', np.nan)\n",
    "data_original = data_original[~data_original['applicant_income_000s'].isna()]\n",
    "\n",
    "print(data_article.shape)\n",
    "print(data_original.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28853be-d37d-496b-bd1f-5cd9143bedfb",
   "metadata": {},
   "source": [
    "### Part 3: My Custom HMDA Data Processing Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d68939-851b-417c-bcf5-73ea7b18f8d6",
   "metadata": {},
   "source": [
    "This code is compatible with any HMDA dataset downloaded from the official website, including data up to the year 2017.\n",
    "\n",
    "You can customize code by selecting which columns and values to filter out—simply adjust the values in the values_to_remove and columns_to_remove dictionaries within the code (but in some cases you will need to change missing values cleaning logic due to some almost empty columns).\n",
    "\n",
    "If you’d like to follow the approach used in the New York dataset from the articles, remove values based on Part 2 output.\n",
    "\n",
    "For a detailed explanation of the numeric codes (the only changed variable is action_taken: 1->0 and 3->1) used in HMDA data check this link: https://files.consumerfinance.gov/hmda-historic-data-dictionaries/lar_record_codes.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8283719f-224d-4bdc-9ea2-5f17b5bbf3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (446902, 78)\n",
      "Final shape after cleaning: (171477, 21)\n"
     ]
    }
   ],
   "source": [
    "data_lending = pd.read_csv(\"hmda_2017_ny_all-records_labels.csv\", low_memory=False)\n",
    "print(f'Original shape: {data_lending.shape}')\n",
    "\n",
    "# Values to remove\n",
    "values_to_remove = {\n",
    "    'action_taken': [2, 4, 5, 6, 7, 8],\n",
    "    'loan_type': [3, 4],\n",
    "    'applicant_race_1': [1, 2, 4, 6, 7],\n",
    "    'lien_status': [3, 4],\n",
    "    'applicant_sex': [3, 4],\n",
    "    'co_applicant_sex': [3, 4],\n",
    "    'co_applicant_race_1': [1, 2, 4, 6, 7],\n",
    "    'applicant_ethnicity': [3, 4],\n",
    "    'co_applicant_ethnicity': [3, 4]\n",
    "}\n",
    "\n",
    "# Filter\n",
    "data_lending_short = data_lending.copy()\n",
    "for col, values in values_to_remove.items():\n",
    "    data_lending_short = data_lending_short[~data_lending_short[col].isin(values)]\n",
    "\n",
    "# Delete columns\n",
    "columns_to_remove = ['as_of_year', 'agency_name', 'agency_abbr', 'agency_code', 'property_type_name',\n",
    "       'property_type', 'owner_occupancy_name', 'owner_occupancy', 'preapproval_name', 'preapproval',\n",
    "       'state_name', 'state_abbr', 'state_code', 'applicant_race_name_2', 'applicant_race_2',\n",
    "       'applicant_race_name_3', 'applicant_race_3', 'applicant_race_name_4', 'applicant_race_4',\n",
    "       'applicant_race_name_5', 'applicant_race_5', 'co_applicant_race_name_2', 'co_applicant_race_2',\n",
    "       'co_applicant_race_name_3', 'co_applicant_race_3', 'co_applicant_race_name_4', 'co_applicant_race_4',\n",
    "       'co_applicant_race_name_5', 'co_applicant_race_5', 'purchaser_type_name', 'purchaser_type',\n",
    "       'denial_reason_name_1', 'denial_reason_1', 'denial_reason_name_2', 'denial_reason_2', 'denial_reason_name_3',\n",
    "       'denial_reason_3', 'rate_spread', 'hoepa_status_name', 'hoepa_status','edit_status_name', 'edit_status',\n",
    "       'sequence_number', 'application_date_indicator', 'respondent_id', 'loan_type_name', 'loan_purpose_name',\n",
    "       'action_taken_name', 'msamd_name', 'county_name', 'applicant_ethnicity_name', 'co_applicant_ethnicity_name',\n",
    "       'applicant_race_name_1', 'co_applicant_race_name_1', 'applicant_sex_name', 'co_applicant_sex_name',\n",
    "       'lien_status_name']\n",
    "\n",
    "data_lending_dropped = data_lending_short.drop(columns=columns_to_remove)\n",
    "\n",
    "# Clean and refactor data\n",
    "data_lending_clean = data_lending_dropped.dropna(axis='index')\n",
    "data_lending_clean.loc[:, 'action_taken'] = data_lending_clean['action_taken'].map({1: 0, 3: 1})\n",
    "print(f'Final shape after cleaning: {data_lending_clean.shape}')\n",
    "\n",
    "# Save\n",
    "data_lending_clean.to_csv(\"cleaned_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
